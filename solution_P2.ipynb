{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2 - permutation-equiriant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing modules\n",
    "from sklearn import metrics\n",
    "\n",
    "# ML modules\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation, MaxPooling1D, Conv1D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# general stuff\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (200000, 15)\n",
      "X_train_3d (200000, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('./data/xtrain-2.csv').drop(['Unnamed: 0'], axis=1) # Removes one column to clean data\n",
    "y_train = pd.read_csv('./data/ytrain-2.csv').drop(['Unnamed: 0'], axis=1)\n",
    "X_test = pd.read_csv('./data/xtest-2.csv').drop(['Unnamed: 0'], axis=1)\n",
    "y_test = pd.read_csv('./data/ytest-2.csv').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "print(f'X_train {X_train.shape}')\n",
    "\n",
    "# Reshape X_train to be right dimentions for conv1D layer (below)\n",
    "X_train_3d = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_3d = X_test.values.reshape(X_test.shape[0], X_train.shape[1], 1)\n",
    "print(f'X_train_3d {X_train_3d.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input features\n",
    "n_features = X_train_3d.shape[1:]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct permutation equivariant neural network\n",
    "def create_p_e_model(L, w):\n",
    "  inputs = Input(shape=(X_train_3d.shape[1], X_train_3d.shape[2]))\n",
    "  print(inputs.shape)\n",
    "  x = inputs\n",
    "  for i in range(L-1):\n",
    "    x = Conv1D(5, w, padding='same', activation='relu', name='conv_layer_{}'.format(i))(x)\n",
    "    x = Activation('relu')(x)\n",
    "  \n",
    "  x = MaxPooling1D(pool_size=x.shape[1])(x)\n",
    "  flatten = Flatten()(x)\n",
    "  outputs = Dense(5)(flatten)\n",
    "\n",
    "  p_e_model = keras.Model(inputs = inputs, outputs=outputs)\n",
    "  \n",
    "  optimizer = Adam(learning_rate=1e-4, epsilon=1e-3)\n",
    "  p_e_model.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
    "  \n",
    "  return p_e_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 1)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 15, 1)]           0         \n",
      "                                                                 \n",
      " conv_layer_0 (Conv1D)       (None, 15, 5)             30        \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 15, 5)             0         \n",
      "                                                                 \n",
      " conv_layer_1 (Conv1D)       (None, 15, 5)             130       \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 15, 5)             0         \n",
      "                                                                 \n",
      " conv_layer_2 (Conv1D)       (None, 15, 5)             130       \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 15, 5)             0         \n",
      "                                                                 \n",
      " conv_layer_3 (Conv1D)       (None, 15, 5)             130       \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 15, 5)             0         \n",
      "                                                                 \n",
      " conv_layer_4 (Conv1D)       (None, 15, 5)             130       \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 15, 5)             0         \n",
      "                                                                 \n",
      " conv_layer_5 (Conv1D)       (None, 15, 5)             130       \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 15, 5)             0         \n",
      "                                                                 \n",
      " conv_layer_6 (Conv1D)       (None, 15, 5)             130       \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 15, 5)             0         \n",
      "                                                                 \n",
      " conv_layer_7 (Conv1D)       (None, 15, 5)             130       \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 15, 5)             0         \n",
      "                                                                 \n",
      " conv_layer_8 (Conv1D)       (None, 15, 5)             130       \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 15, 5)             0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 1, 5)             0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,100\n",
      "Trainable params: 1,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "p_e_model = create_p_e_model(L=10,w=5)\n",
    "p_e_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for generating attached image\n",
    "# plot_model(p_e_model, 'p_e_model_model.png', show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of implementation:\n",
    "- This model uses the Functional API from Keras. I chose that, not the sequential as it provides more flexibility.\n",
    "- the function accepts two parameters (L, w), which gets pased down. L being number of layers and w being inserted to the first conv1D layer as the `kernel_size`. By having the `filter`to 5 (m) it creates `mxw` dimention.\n",
    "- For the L-1 layers there is a consists of an equivariant affine transformation followed by ReLU activation layer. \n",
    "- Conv1D makes sure the network is eqivariant as it independantly applyes filters to each feature channel. In that way the network learns features that are equivarant to transformations within each channel.\n",
    "- Then there is a maxPooling layer that that takes the maximum value over each feature channel of the output of the last convolutional layer. This ensures to create a translation-equivariant neural network that is invariant to the ordering of the input sequence.\n",
    "- It is then flattened and passed to the output layer with 5 (m) dimentions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: (2, 5)\n",
      "-----------------------------\n",
      "\n",
      "(None, 15, 1)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 15:57:11.891043: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-24 15:57:12.365149: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/600 [============================>.] - ETA: 0s - loss: 0.7503 - accuracy: 0.2002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 15:57:17.885014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 6s 8ms/step - loss: 0.7481 - accuracy: 0.2003 - val_loss: 0.5011 - val_accuracy: 0.2017\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.3715 - accuracy: 0.1999 - val_loss: 0.2797 - val_accuracy: 0.2033\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2353 - accuracy: 0.1998 - val_loss: 0.2064 - val_accuracy: 0.2029\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1939 - accuracy: 0.2009 - val_loss: 0.1861 - val_accuracy: 0.2000\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1818 - accuracy: 0.2008 - val_loss: 0.1787 - val_accuracy: 0.2025\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1760 - accuracy: 0.2010 - val_loss: 0.1740 - val_accuracy: 0.2018\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1720 - accuracy: 0.2015 - val_loss: 0.1706 - val_accuracy: 0.2024\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1691 - accuracy: 0.2012 - val_loss: 0.1681 - val_accuracy: 0.2046\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1669 - accuracy: 0.2007 - val_loss: 0.1663 - val_accuracy: 0.2029\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1653 - accuracy: 0.2013 - val_loss: 0.1649 - val_accuracy: 0.2007\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1642 - accuracy: 0.2011 - val_loss: 0.1640 - val_accuracy: 0.1996\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1633 - accuracy: 0.2014 - val_loss: 0.1633 - val_accuracy: 0.1959\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1627 - accuracy: 0.2013 - val_loss: 0.1627 - val_accuracy: 0.1956\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1622 - accuracy: 0.2014 - val_loss: 0.1622 - val_accuracy: 0.1973\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1618 - accuracy: 0.2016 - val_loss: 0.1618 - val_accuracy: 0.1970\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1615 - accuracy: 0.2015 - val_loss: 0.1615 - val_accuracy: 0.1973\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1612 - accuracy: 0.2006 - val_loss: 0.1613 - val_accuracy: 0.1990\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.1610 - accuracy: 0.2016 - val_loss: 0.1610 - val_accuracy: 0.1987\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1608 - accuracy: 0.2016 - val_loss: 0.1609 - val_accuracy: 0.1989\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1607 - accuracy: 0.2017 - val_loss: 0.1607 - val_accuracy: 0.1991\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1606 - accuracy: 0.2011 - val_loss: 0.1606 - val_accuracy: 0.1985\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1605 - accuracy: 0.2024 - val_loss: 0.1605 - val_accuracy: 0.1983\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1604 - accuracy: 0.2014 - val_loss: 0.1605 - val_accuracy: 0.1972\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1604 - accuracy: 0.2014 - val_loss: 0.1604 - val_accuracy: 0.1997\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1603 - accuracy: 0.2005 - val_loss: 0.1603 - val_accuracy: 0.1993\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1603 - accuracy: 0.2003 - val_loss: 0.1603 - val_accuracy: 0.1992\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1602 - accuracy: 0.2009 - val_loss: 0.1603 - val_accuracy: 0.1996\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1602 - accuracy: 0.2004 - val_loss: 0.1602 - val_accuracy: 0.2007\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1602 - accuracy: 0.1998 - val_loss: 0.1602 - val_accuracy: 0.1995\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1602 - accuracy: 0.2013 - val_loss: 0.1602 - val_accuracy: 0.1978\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1602 - accuracy: 0.2000 - val_loss: 0.1602 - val_accuracy: 0.2000\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1602 - accuracy: 0.2008 - val_loss: 0.1602 - val_accuracy: 0.1997\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1999 - val_loss: 0.1602 - val_accuracy: 0.1969\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2017 - val_loss: 0.1602 - val_accuracy: 0.2004\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2007 - val_loss: 0.1602 - val_accuracy: 0.1952\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2006 - val_loss: 0.1602 - val_accuracy: 0.1984\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2009 - val_loss: 0.1601 - val_accuracy: 0.2017\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2010 - val_loss: 0.1602 - val_accuracy: 0.1985\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2013 - val_loss: 0.1601 - val_accuracy: 0.1941\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2001 - val_loss: 0.1601 - val_accuracy: 0.1979\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2018 - val_loss: 0.1601 - val_accuracy: 0.1974\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2005 - val_loss: 0.1601 - val_accuracy: 0.1972\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2005 - val_loss: 0.1601 - val_accuracy: 0.1992\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1999 - val_loss: 0.1601 - val_accuracy: 0.1998\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2000 - val_loss: 0.1601 - val_accuracy: 0.1956\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2001 - val_loss: 0.1601 - val_accuracy: 0.1939\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2006 - val_loss: 0.1601 - val_accuracy: 0.1952\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1992 - val_loss: 0.1601 - val_accuracy: 0.2001\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2005 - val_loss: 0.1601 - val_accuracy: 0.1966\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1995 - val_loss: 0.1601 - val_accuracy: 0.1980\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2009 - val_loss: 0.1601 - val_accuracy: 0.1941\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1994 - val_loss: 0.1601 - val_accuracy: 0.1967\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2011 - val_loss: 0.1601 - val_accuracy: 0.1988\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2001 - val_loss: 0.1601 - val_accuracy: 0.2012\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2007 - val_loss: 0.1601 - val_accuracy: 0.1989\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2002 - val_loss: 0.1601 - val_accuracy: 0.2002\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2016 - val_loss: 0.1601 - val_accuracy: 0.2003\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1997 - val_loss: 0.1601 - val_accuracy: 0.1978\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2010 - val_loss: 0.1601 - val_accuracy: 0.1973\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2015 - val_loss: 0.1601 - val_accuracy: 0.1974\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2002 - val_loss: 0.1601 - val_accuracy: 0.1985\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2003 - val_loss: 0.1601 - val_accuracy: 0.1982\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2008 - val_loss: 0.1601 - val_accuracy: 0.1958\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1997 - val_loss: 0.1601 - val_accuracy: 0.1978\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1997 - val_loss: 0.1601 - val_accuracy: 0.1997\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2007 - val_loss: 0.1601 - val_accuracy: 0.1946\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2000 - val_loss: 0.1601 - val_accuracy: 0.1958\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2012 - val_loss: 0.1601 - val_accuracy: 0.1988\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2020 - val_loss: 0.1601 - val_accuracy: 0.1971\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2002 - val_loss: 0.1601 - val_accuracy: 0.1984\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1998 - val_loss: 0.1601 - val_accuracy: 0.1972\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2010 - val_loss: 0.1601 - val_accuracy: 0.1976\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1999 - val_loss: 0.1601 - val_accuracy: 0.2000\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2014 - val_loss: 0.1601 - val_accuracy: 0.1987\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2008 - val_loss: 0.1601 - val_accuracy: 0.1991\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1994 - val_loss: 0.1601 - val_accuracy: 0.1978\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2008 - val_loss: 0.1601 - val_accuracy: 0.2002\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2005 - val_loss: 0.1601 - val_accuracy: 0.1950\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2010 - val_loss: 0.1601 - val_accuracy: 0.1989\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.1997 - val_loss: 0.1601 - val_accuracy: 0.1995\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2012 - val_loss: 0.1601 - val_accuracy: 0.1970\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2003 - val_loss: 0.1601 - val_accuracy: 0.1946\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2011 - val_loss: 0.1601 - val_accuracy: 0.1989\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2011 - val_loss: 0.1601 - val_accuracy: 0.2037\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2017 - val_loss: 0.1601 - val_accuracy: 0.1975\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2014 - val_loss: 0.1601 - val_accuracy: 0.1956\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2012 - val_loss: 0.1601 - val_accuracy: 0.1976\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2001 - val_loss: 0.1601 - val_accuracy: 0.1953\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2012 - val_loss: 0.1601 - val_accuracy: 0.1957\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2001 - val_loss: 0.1601 - val_accuracy: 0.1989\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.1996 - val_loss: 0.1601 - val_accuracy: 0.1999\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2009 - val_loss: 0.1601 - val_accuracy: 0.1951\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2016 - val_loss: 0.1601 - val_accuracy: 0.1962\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.1999 - val_loss: 0.1601 - val_accuracy: 0.1969\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2015 - val_loss: 0.1601 - val_accuracy: 0.1970\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2008 - val_loss: 0.1601 - val_accuracy: 0.1991\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2008 - val_loss: 0.1601 - val_accuracy: 0.2016\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.1988 - val_loss: 0.1601 - val_accuracy: 0.2006\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.1988 - val_loss: 0.1601 - val_accuracy: 0.1951\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2005 - val_loss: 0.1600 - val_accuracy: 0.1981\n",
      "  87/6250 [..............................] - ETA: 10s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:04:17.359792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 11s 2ms/step\n",
      "--- Final score (RMSE) : 0.40004468907941915\n",
      "-----------------------------\n",
      "\n",
      "Values: (2, 10)\n",
      "-----------------------------\n",
      "\n",
      "(None, 15, 1)\n",
      "Epoch 1/100\n",
      "  9/600 [..............................] - ETA: 4s - loss: 1.4207 - accuracy: 0.2067  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:04:31.107941: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/600 [============================>.] - ETA: 0s - loss: 0.9156 - accuracy: 0.1991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:04:35.345348: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 5s 8ms/step - loss: 0.9133 - accuracy: 0.1990 - val_loss: 0.5695 - val_accuracy: 0.2004\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.4168 - accuracy: 0.1991 - val_loss: 0.3121 - val_accuracy: 0.2017\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2599 - accuracy: 0.1993 - val_loss: 0.2226 - val_accuracy: 0.2030\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2026 - accuracy: 0.1994 - val_loss: 0.1879 - val_accuracy: 0.2020\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1794 - accuracy: 0.2009 - val_loss: 0.1731 - val_accuracy: 0.2011\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1692 - accuracy: 0.2004 - val_loss: 0.1665 - val_accuracy: 0.1999\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1648 - accuracy: 0.2000 - val_loss: 0.1638 - val_accuracy: 0.2011\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1630 - accuracy: 0.1999 - val_loss: 0.1627 - val_accuracy: 0.2006\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1622 - accuracy: 0.2004 - val_loss: 0.1621 - val_accuracy: 0.1984\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1617 - accuracy: 0.2010 - val_loss: 0.1616 - val_accuracy: 0.1996\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1613 - accuracy: 0.2014 - val_loss: 0.1613 - val_accuracy: 0.1998\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1610 - accuracy: 0.2009 - val_loss: 0.1610 - val_accuracy: 0.1973\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1607 - accuracy: 0.2010 - val_loss: 0.1607 - val_accuracy: 0.1969\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1605 - accuracy: 0.2010 - val_loss: 0.1605 - val_accuracy: 0.1984\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1604 - accuracy: 0.2008 - val_loss: 0.1604 - val_accuracy: 0.1997\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1603 - accuracy: 0.2017 - val_loss: 0.1603 - val_accuracy: 0.2003\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1602 - accuracy: 0.2025 - val_loss: 0.1602 - val_accuracy: 0.2032\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2016 - val_loss: 0.1602 - val_accuracy: 0.2023\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2017 - val_loss: 0.1601 - val_accuracy: 0.2028\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2020 - val_loss: 0.1601 - val_accuracy: 0.2015\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2016 - val_loss: 0.1601 - val_accuracy: 0.2035\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2018 - val_loss: 0.1601 - val_accuracy: 0.2022\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2022 - val_loss: 0.1601 - val_accuracy: 0.2061\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2005 - val_loss: 0.1601 - val_accuracy: 0.2020\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2026 - val_loss: 0.1601 - val_accuracy: 0.2008\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2006 - val_loss: 0.1601 - val_accuracy: 0.2003\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2017 - val_loss: 0.1601 - val_accuracy: 0.2033\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2013 - val_loss: 0.1601 - val_accuracy: 0.2059\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2025 - val_loss: 0.1601 - val_accuracy: 0.2034\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2019 - val_loss: 0.1600 - val_accuracy: 0.2029\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2018 - val_loss: 0.1600 - val_accuracy: 0.2047\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2022 - val_loss: 0.1600 - val_accuracy: 0.2033\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2020 - val_loss: 0.1600 - val_accuracy: 0.2042\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2027 - val_loss: 0.1600 - val_accuracy: 0.2028\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2023 - val_loss: 0.1600 - val_accuracy: 0.2009\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2026 - val_loss: 0.1600 - val_accuracy: 0.1993\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2026 - val_loss: 0.1600 - val_accuracy: 0.2000\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2020 - val_loss: 0.1600 - val_accuracy: 0.2003\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2016 - val_loss: 0.1600 - val_accuracy: 0.2028\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2012 - val_loss: 0.1600 - val_accuracy: 0.2012\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2022 - val_loss: 0.1600 - val_accuracy: 0.2005\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2018 - val_loss: 0.1600 - val_accuracy: 0.1965\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2013 - val_loss: 0.1600 - val_accuracy: 0.2001\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2007 - val_loss: 0.1600 - val_accuracy: 0.1994\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2017 - val_loss: 0.1600 - val_accuracy: 0.1987\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2016 - val_loss: 0.1600 - val_accuracy: 0.1969\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2007 - val_loss: 0.1600 - val_accuracy: 0.1972\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2020 - val_loss: 0.1600 - val_accuracy: 0.2001\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2030 - val_loss: 0.1600 - val_accuracy: 0.2027\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2025 - val_loss: 0.1600 - val_accuracy: 0.1997\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2023 - val_loss: 0.1600 - val_accuracy: 0.2011\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2021 - val_loss: 0.1600 - val_accuracy: 0.2014\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2024 - val_loss: 0.1600 - val_accuracy: 0.2035\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2013 - val_loss: 0.1600 - val_accuracy: 0.1995\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2021 - val_loss: 0.1600 - val_accuracy: 0.1987\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2017 - val_loss: 0.1600 - val_accuracy: 0.2016\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2022 - val_loss: 0.1600 - val_accuracy: 0.2000\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2015 - val_loss: 0.1600 - val_accuracy: 0.1995\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2017 - val_loss: 0.1600 - val_accuracy: 0.2057\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2017 - val_loss: 0.1600 - val_accuracy: 0.2007\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2019 - val_loss: 0.1600 - val_accuracy: 0.2010\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2021 - val_loss: 0.1600 - val_accuracy: 0.2045\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2030 - val_loss: 0.1600 - val_accuracy: 0.2012\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2020 - val_loss: 0.1600 - val_accuracy: 0.2024\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2022 - val_loss: 0.1600 - val_accuracy: 0.2018\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2027 - val_loss: 0.1600 - val_accuracy: 0.1996\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2024 - val_loss: 0.1600 - val_accuracy: 0.1981\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2025 - val_loss: 0.1600 - val_accuracy: 0.2001\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2029 - val_loss: 0.1600 - val_accuracy: 0.1971\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2022 - val_loss: 0.1600 - val_accuracy: 0.1991\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2015 - val_loss: 0.1600 - val_accuracy: 0.2012\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2017 - val_loss: 0.1600 - val_accuracy: 0.2032\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2026 - val_loss: 0.1600 - val_accuracy: 0.2020\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2013 - val_loss: 0.1600 - val_accuracy: 0.2019\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2031 - val_loss: 0.1600 - val_accuracy: 0.2003\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2002 - val_loss: 0.1600 - val_accuracy: 0.1992\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2031 - val_loss: 0.1600 - val_accuracy: 0.1994\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2016 - val_loss: 0.1600 - val_accuracy: 0.1980\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2024 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2029 - val_loss: 0.1600 - val_accuracy: 0.2011\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2021 - val_loss: 0.1600 - val_accuracy: 0.2028\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2036 - val_loss: 0.1600 - val_accuracy: 0.2006\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2020 - val_loss: 0.1600 - val_accuracy: 0.2024\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2023 - val_loss: 0.1600 - val_accuracy: 0.1984\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2020 - val_loss: 0.1600 - val_accuracy: 0.1978\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2013 - val_loss: 0.1600 - val_accuracy: 0.2036\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2021 - val_loss: 0.1600 - val_accuracy: 0.1981\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2015 - val_loss: 0.1600 - val_accuracy: 0.2025\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2016 - val_loss: 0.1600 - val_accuracy: 0.2016\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2018 - val_loss: 0.1600 - val_accuracy: 0.2031\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2018 - val_loss: 0.1600 - val_accuracy: 0.2037\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2023 - val_loss: 0.1600 - val_accuracy: 0.2012\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2023 - val_loss: 0.1600 - val_accuracy: 0.2001\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2017 - val_loss: 0.1600 - val_accuracy: 0.2009\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2019 - val_loss: 0.1600 - val_accuracy: 0.1986\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2032 - val_loss: 0.1600 - val_accuracy: 0.2019\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2012 - val_loss: 0.1600 - val_accuracy: 0.1973\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2014 - val_loss: 0.1600 - val_accuracy: 0.2009\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2015 - val_loss: 0.1600 - val_accuracy: 0.1987\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2030 - val_loss: 0.1600 - val_accuracy: 0.2013\n",
      " 102/6250 [..............................] - ETA: 9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:11:37.699554: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 10s 2ms/step\n",
      "--- Final score (RMSE) : 0.4000198583672204\n",
      "-----------------------------\n",
      "\n",
      "Values: (2, 100)\n",
      "-----------------------------\n",
      "\n",
      "(None, 15, 1)\n",
      "Epoch 1/100\n",
      "  8/600 [..............................] - ETA: 4s - loss: 0.2521 - accuracy: 0.1917  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:11:48.549907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.1994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:11:52.945349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1942 - accuracy: 0.1994 - val_loss: 0.1718 - val_accuracy: 0.1993\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1668 - accuracy: 0.1981 - val_loss: 0.1640 - val_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1630 - accuracy: 0.1999 - val_loss: 0.1624 - val_accuracy: 0.2023\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1620 - accuracy: 0.2003 - val_loss: 0.1617 - val_accuracy: 0.1993\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1614 - accuracy: 0.2008 - val_loss: 0.1613 - val_accuracy: 0.2003\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1610 - accuracy: 0.2010 - val_loss: 0.1609 - val_accuracy: 0.1997\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1608 - accuracy: 0.2022 - val_loss: 0.1607 - val_accuracy: 0.1985\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1605 - accuracy: 0.2023 - val_loss: 0.1604 - val_accuracy: 0.1968\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1604 - accuracy: 0.2020 - val_loss: 0.1603 - val_accuracy: 0.1964\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1603 - accuracy: 0.2022 - val_loss: 0.1602 - val_accuracy: 0.1974\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1602 - accuracy: 0.2033 - val_loss: 0.1602 - val_accuracy: 0.1986\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2026 - val_loss: 0.1602 - val_accuracy: 0.1975\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2033 - val_loss: 0.1601 - val_accuracy: 0.2011\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.1601 - accuracy: 0.2027 - val_loss: 0.1601 - val_accuracy: 0.1986\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2035 - val_loss: 0.1601 - val_accuracy: 0.1980\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2046 - val_loss: 0.1601 - val_accuracy: 0.2001\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2021 - val_loss: 0.1601 - val_accuracy: 0.1994\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2033 - val_loss: 0.1601 - val_accuracy: 0.1996\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2036 - val_loss: 0.1600 - val_accuracy: 0.2028\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2034 - val_loss: 0.1601 - val_accuracy: 0.1979\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2032 - val_loss: 0.1601 - val_accuracy: 0.1992\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2039 - val_loss: 0.1600 - val_accuracy: 0.2005\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2032 - val_loss: 0.1600 - val_accuracy: 0.2013\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2031 - val_loss: 0.1600 - val_accuracy: 0.2022\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2040 - val_loss: 0.1600 - val_accuracy: 0.2037\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2034 - val_loss: 0.1600 - val_accuracy: 0.1977\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2042 - val_loss: 0.1600 - val_accuracy: 0.2009\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2015\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2036 - val_loss: 0.1600 - val_accuracy: 0.2011\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2001\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.1976\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2048 - val_loss: 0.1600 - val_accuracy: 0.2031\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2042 - val_loss: 0.1600 - val_accuracy: 0.1998\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1601 - val_accuracy: 0.1978\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.1954\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1600 - val_accuracy: 0.1979\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.1999\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1600 - val_accuracy: 0.2014\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2043 - val_loss: 0.1600 - val_accuracy: 0.2021\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2052 - val_loss: 0.1600 - val_accuracy: 0.2005\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2057\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1601 - val_accuracy: 0.1971\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.1996\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2013\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2058\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2030\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2055 - val_loss: 0.1600 - val_accuracy: 0.1992\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2055 - val_loss: 0.1600 - val_accuracy: 0.1981\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2062 - val_loss: 0.1600 - val_accuracy: 0.1982\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2052 - val_loss: 0.1600 - val_accuracy: 0.2006\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1600 - val_accuracy: 0.2005\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2060 - val_loss: 0.1600 - val_accuracy: 0.1990\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.1978\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1600 - val_accuracy: 0.2003\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.2024\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1600 - val_accuracy: 0.2009\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2042 - val_loss: 0.1600 - val_accuracy: 0.1980\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2045 - val_loss: 0.1600 - val_accuracy: 0.1989\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1600 - val_accuracy: 0.2012\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2040 - val_loss: 0.1600 - val_accuracy: 0.1993\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2069 - val_loss: 0.1600 - val_accuracy: 0.1986\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.1984\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2054 - val_loss: 0.1600 - val_accuracy: 0.2006\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.2039\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2045 - val_loss: 0.1600 - val_accuracy: 0.2026\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.1977\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2067 - val_loss: 0.1600 - val_accuracy: 0.1992\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2043 - val_loss: 0.1600 - val_accuracy: 0.1962\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2021\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2052 - val_loss: 0.1600 - val_accuracy: 0.2017\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2040 - val_loss: 0.1600 - val_accuracy: 0.1990\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2048 - val_loss: 0.1600 - val_accuracy: 0.1992\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2062 - val_loss: 0.1600 - val_accuracy: 0.1984\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.1960\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2037 - val_loss: 0.1600 - val_accuracy: 0.2002\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.1996\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2059 - val_loss: 0.1600 - val_accuracy: 0.2001\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.1995\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2061 - val_loss: 0.1600 - val_accuracy: 0.1978\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2059 - val_loss: 0.1600 - val_accuracy: 0.2015\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2063 - val_loss: 0.1600 - val_accuracy: 0.2016\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2061 - val_loss: 0.1600 - val_accuracy: 0.1991\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2059 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2059 - val_loss: 0.1600 - val_accuracy: 0.1972\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2063 - val_loss: 0.1600 - val_accuracy: 0.2023\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2058 - val_loss: 0.1600 - val_accuracy: 0.1982\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.2003\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2052 - val_loss: 0.1600 - val_accuracy: 0.1996\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2060 - val_loss: 0.1600 - val_accuracy: 0.2002\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.1987\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2065 - val_loss: 0.1600 - val_accuracy: 0.1989\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1600 - val_accuracy: 0.1975\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2061 - val_loss: 0.1601 - val_accuracy: 0.1990\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1601 - val_accuracy: 0.2015\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.1985\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2063 - val_loss: 0.1601 - val_accuracy: 0.2014\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.1993\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2063 - val_loss: 0.1601 - val_accuracy: 0.1985\n",
      "  82/6250 [..............................] - ETA: 11s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:19:19.663998: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 10s 2ms/step\n",
      "--- Final score (RMSE) : 0.4000501363437163\n",
      "-----------------------------\n",
      "\n",
      "Values: (2, 200)\n",
      "-----------------------------\n",
      "\n",
      "(None, 15, 1)\n",
      "Epoch 1/100\n",
      "  7/600 [..............................] - ETA: 5s - loss: 0.2670 - accuracy: 0.1986  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:19:30.833872: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/600 [============================>.] - ETA: 0s - loss: 0.1962 - accuracy: 0.1992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:19:35.516292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1960 - accuracy: 0.1991 - val_loss: 0.1666 - val_accuracy: 0.1975\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1635 - accuracy: 0.1992 - val_loss: 0.1624 - val_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1620 - accuracy: 0.1995 - val_loss: 0.1618 - val_accuracy: 0.1982\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1615 - accuracy: 0.2016 - val_loss: 0.1613 - val_accuracy: 0.1954\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1612 - accuracy: 0.2022 - val_loss: 0.1610 - val_accuracy: 0.1995\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1609 - accuracy: 0.2021 - val_loss: 0.1607 - val_accuracy: 0.1994\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1606 - accuracy: 0.2028 - val_loss: 0.1605 - val_accuracy: 0.2015\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1604 - accuracy: 0.2016 - val_loss: 0.1604 - val_accuracy: 0.2005\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1603 - accuracy: 0.2021 - val_loss: 0.1602 - val_accuracy: 0.2016\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1602 - accuracy: 0.2028 - val_loss: 0.1602 - val_accuracy: 0.2021\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2034 - val_loss: 0.1601 - val_accuracy: 0.2011\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2031 - val_loss: 0.1601 - val_accuracy: 0.2001\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2030 - val_loss: 0.1600 - val_accuracy: 0.1982\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2034 - val_loss: 0.1600 - val_accuracy: 0.2010\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2028 - val_loss: 0.1600 - val_accuracy: 0.2038\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2032 - val_loss: 0.1600 - val_accuracy: 0.1998\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2032 - val_loss: 0.1600 - val_accuracy: 0.2040\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2032 - val_loss: 0.1600 - val_accuracy: 0.2001\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2034 - val_loss: 0.1600 - val_accuracy: 0.2015\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2043 - val_loss: 0.1600 - val_accuracy: 0.2042\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2056\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2039\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2037 - val_loss: 0.1600 - val_accuracy: 0.2014\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2047\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2032 - val_loss: 0.1600 - val_accuracy: 0.2010\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2039 - val_loss: 0.1600 - val_accuracy: 0.2028\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2043 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2043 - val_loss: 0.1600 - val_accuracy: 0.1995\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2024 - val_loss: 0.1600 - val_accuracy: 0.2005\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2048 - val_loss: 0.1600 - val_accuracy: 0.2003\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2034 - val_loss: 0.1600 - val_accuracy: 0.2007\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2039 - val_loss: 0.1600 - val_accuracy: 0.2048\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2033\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2047\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2048 - val_loss: 0.1600 - val_accuracy: 0.2036\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2016\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2055 - val_loss: 0.1600 - val_accuracy: 0.2002\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2042\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2027\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2040 - val_loss: 0.1600 - val_accuracy: 0.2047\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2041 - val_loss: 0.1600 - val_accuracy: 0.2043\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2042 - val_loss: 0.1600 - val_accuracy: 0.2030\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2018\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2007\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2041 - val_loss: 0.1600 - val_accuracy: 0.2028\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2036 - val_loss: 0.1600 - val_accuracy: 0.2023\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2045 - val_loss: 0.1600 - val_accuracy: 0.2028\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1600 - val_accuracy: 0.2042\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1600 - val_accuracy: 0.2032\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2002\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2037\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1600 - val_accuracy: 0.2032\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2039 - val_loss: 0.1600 - val_accuracy: 0.2025\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2055 - val_loss: 0.1600 - val_accuracy: 0.2027\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2048 - val_loss: 0.1600 - val_accuracy: 0.2011\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2033 - val_loss: 0.1600 - val_accuracy: 0.2016\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2039 - val_loss: 0.1600 - val_accuracy: 0.2038\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2043 - val_loss: 0.1600 - val_accuracy: 0.2014\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2030\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2045 - val_loss: 0.1600 - val_accuracy: 0.2032\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1600 - val_accuracy: 0.2023\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1600 - val_accuracy: 0.2024\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2051\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2043\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2039 - val_loss: 0.1600 - val_accuracy: 0.2019\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2045 - val_loss: 0.1600 - val_accuracy: 0.2028\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.2011\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2045 - val_loss: 0.1600 - val_accuracy: 0.2004\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2059 - val_loss: 0.1600 - val_accuracy: 0.2033\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2054 - val_loss: 0.1600 - val_accuracy: 0.2032\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2003\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1600 - val_accuracy: 0.2022\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2040 - val_loss: 0.1600 - val_accuracy: 0.2019\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2030\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2041\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.2016\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2048 - val_loss: 0.1600 - val_accuracy: 0.2025\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2011\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2003\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2049\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.2031\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.2034\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.2019\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2042 - val_loss: 0.1600 - val_accuracy: 0.2003\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2059 - val_loss: 0.1600 - val_accuracy: 0.2039\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.1992\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1600 - val_accuracy: 0.2043\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2031\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1600 - val_accuracy: 0.2027\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1600 - val_accuracy: 0.2039\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2030\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2042 - val_loss: 0.1600 - val_accuracy: 0.2040\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2055 - val_loss: 0.1600 - val_accuracy: 0.2000\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2043 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2064 - val_loss: 0.1600 - val_accuracy: 0.2046\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2037\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1600 - val_accuracy: 0.2018\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1600 - val_accuracy: 0.2006\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2021\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2065\n",
      "  94/6250 [..............................] - ETA: 10s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:27:18.949855: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 10s 2ms/step\n",
      "--- Final score (RMSE) : 0.4000289125262223\n",
      "-----------------------------\n",
      "\n",
      "Values: (3, 5)\n",
      "-----------------------------\n",
      "\n",
      "(None, 15, 1)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:27:30.451476: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/600 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.2010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:27:35.108124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2219 - accuracy: 0.2011 - val_loss: 0.1796 - val_accuracy: 0.1977\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1710 - accuracy: 0.2021 - val_loss: 0.1671 - val_accuracy: 0.1979\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1657 - accuracy: 0.2024 - val_loss: 0.1651 - val_accuracy: 0.2001\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1643 - accuracy: 0.2026 - val_loss: 0.1640 - val_accuracy: 0.1998\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1634 - accuracy: 0.2027 - val_loss: 0.1632 - val_accuracy: 0.2015\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1627 - accuracy: 0.2021 - val_loss: 0.1625 - val_accuracy: 0.2031\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1622 - accuracy: 0.2029 - val_loss: 0.1620 - val_accuracy: 0.2016\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1617 - accuracy: 0.2026 - val_loss: 0.1617 - val_accuracy: 0.2010\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1614 - accuracy: 0.2014 - val_loss: 0.1613 - val_accuracy: 0.2031\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1612 - accuracy: 0.2014 - val_loss: 0.1611 - val_accuracy: 0.2033\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1610 - accuracy: 0.2012 - val_loss: 0.1609 - val_accuracy: 0.2027\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1608 - accuracy: 0.2009 - val_loss: 0.1608 - val_accuracy: 0.1998\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1607 - accuracy: 0.2007 - val_loss: 0.1606 - val_accuracy: 0.2021\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1606 - accuracy: 0.2009 - val_loss: 0.1605 - val_accuracy: 0.2009\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1605 - accuracy: 0.2017 - val_loss: 0.1605 - val_accuracy: 0.2019\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1604 - accuracy: 0.2012 - val_loss: 0.1604 - val_accuracy: 0.2014\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1603 - accuracy: 0.2012 - val_loss: 0.1603 - val_accuracy: 0.2040\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1603 - accuracy: 0.2017 - val_loss: 0.1603 - val_accuracy: 0.2030\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1603 - accuracy: 0.2019 - val_loss: 0.1603 - val_accuracy: 0.2039\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1602 - accuracy: 0.2024 - val_loss: 0.1602 - val_accuracy: 0.2032\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1602 - accuracy: 0.2023 - val_loss: 0.1602 - val_accuracy: 0.2022\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1602 - accuracy: 0.2019 - val_loss: 0.1602 - val_accuracy: 0.2027\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1602 - accuracy: 0.2018 - val_loss: 0.1602 - val_accuracy: 0.2002\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2018 - val_loss: 0.1601 - val_accuracy: 0.2006\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2024 - val_loss: 0.1601 - val_accuracy: 0.2008\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2018 - val_loss: 0.1601 - val_accuracy: 0.2011\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2027 - val_loss: 0.1601 - val_accuracy: 0.2009\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2027 - val_loss: 0.1601 - val_accuracy: 0.1992\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2028 - val_loss: 0.1601 - val_accuracy: 0.2002\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2022 - val_loss: 0.1601 - val_accuracy: 0.2010\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2026 - val_loss: 0.1601 - val_accuracy: 0.2003\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2029 - val_loss: 0.1601 - val_accuracy: 0.2016\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2034 - val_loss: 0.1601 - val_accuracy: 0.2009\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2018 - val_loss: 0.1601 - val_accuracy: 0.1986\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2034 - val_loss: 0.1601 - val_accuracy: 0.1982\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2035 - val_loss: 0.1601 - val_accuracy: 0.2004\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2036 - val_loss: 0.1601 - val_accuracy: 0.2006\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2039 - val_loss: 0.1601 - val_accuracy: 0.2023\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2037 - val_loss: 0.1601 - val_accuracy: 0.1993\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2041 - val_loss: 0.1601 - val_accuracy: 0.1989\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1601 - val_accuracy: 0.2013\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2020\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2042 - val_loss: 0.1600 - val_accuracy: 0.2005\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2041 - val_loss: 0.1600 - val_accuracy: 0.2000\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2040 - val_loss: 0.1600 - val_accuracy: 0.2023\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.2012\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2024\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2022\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1600 - val_accuracy: 0.2052\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.2045\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.2041\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2060 - val_loss: 0.1600 - val_accuracy: 0.2036\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2058 - val_loss: 0.1600 - val_accuracy: 0.2003\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2062 - val_loss: 0.1600 - val_accuracy: 0.2007\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1600 - val_accuracy: 0.2060\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2058 - val_loss: 0.1600 - val_accuracy: 0.2037\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2058 - val_loss: 0.1600 - val_accuracy: 0.2049\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2061 - val_loss: 0.1600 - val_accuracy: 0.2036\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2063 - val_loss: 0.1600 - val_accuracy: 0.2012\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2065 - val_loss: 0.1600 - val_accuracy: 0.1983\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1600 - val_accuracy: 0.2042\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2064 - val_loss: 0.1600 - val_accuracy: 0.2055\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.2063\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2063 - val_loss: 0.1600 - val_accuracy: 0.2051\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2068 - val_loss: 0.1600 - val_accuracy: 0.2016\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2068 - val_loss: 0.1600 - val_accuracy: 0.1991\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2065 - val_loss: 0.1600 - val_accuracy: 0.2024\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2072 - val_loss: 0.1600 - val_accuracy: 0.2006\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2069 - val_loss: 0.1600 - val_accuracy: 0.2035\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2082 - val_loss: 0.1600 - val_accuracy: 0.2014\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2063 - val_loss: 0.1600 - val_accuracy: 0.2029\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2075 - val_loss: 0.1600 - val_accuracy: 0.2048\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2068 - val_loss: 0.1600 - val_accuracy: 0.2029\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2062 - val_loss: 0.1600 - val_accuracy: 0.2059\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2063 - val_loss: 0.1600 - val_accuracy: 0.1989\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2070 - val_loss: 0.1600 - val_accuracy: 0.2031\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2078 - val_loss: 0.1600 - val_accuracy: 0.2004\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2064 - val_loss: 0.1600 - val_accuracy: 0.2009\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2079 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2069 - val_loss: 0.1600 - val_accuracy: 0.2025\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2078 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2074 - val_loss: 0.1600 - val_accuracy: 0.2007\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2065 - val_loss: 0.1600 - val_accuracy: 0.1986\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2075 - val_loss: 0.1600 - val_accuracy: 0.2013\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2061 - val_loss: 0.1600 - val_accuracy: 0.2029\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2072 - val_loss: 0.1600 - val_accuracy: 0.2021\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2068 - val_loss: 0.1600 - val_accuracy: 0.2029\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2075 - val_loss: 0.1600 - val_accuracy: 0.1997\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2088 - val_loss: 0.1600 - val_accuracy: 0.2060\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2071 - val_loss: 0.1600 - val_accuracy: 0.2046\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2073 - val_loss: 0.1600 - val_accuracy: 0.2000\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2071 - val_loss: 0.1600 - val_accuracy: 0.2004\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2080 - val_loss: 0.1600 - val_accuracy: 0.2050\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2078 - val_loss: 0.1600 - val_accuracy: 0.2018\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2070 - val_loss: 0.1600 - val_accuracy: 0.2012\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2074 - val_loss: 0.1600 - val_accuracy: 0.2048\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2076 - val_loss: 0.1600 - val_accuracy: 0.2033\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2074 - val_loss: 0.1600 - val_accuracy: 0.2021\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2076 - val_loss: 0.1600 - val_accuracy: 0.2043\n",
      "  69/6250 [..............................] - ETA: 13s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:35:00.300561: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 11s 2ms/step\n",
      "--- Final score (RMSE) : 0.3999953687227674\n",
      "-----------------------------\n",
      "\n",
      "Values: (3, 10)\n",
      "-----------------------------\n",
      "\n",
      "(None, 15, 1)\n",
      "Epoch 1/100\n",
      "  1/600 [..............................] - ETA: 3:10 - loss: 0.3216 - accuracy: 0.2467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:35:12.737978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598/600 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.1993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:35:17.264089: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2044 - accuracy: 0.1993 - val_loss: 0.1728 - val_accuracy: 0.2045\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1704 - accuracy: 0.2005 - val_loss: 0.1682 - val_accuracy: 0.2068\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1671 - accuracy: 0.2005 - val_loss: 0.1658 - val_accuracy: 0.2058\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1651 - accuracy: 0.2014 - val_loss: 0.1642 - val_accuracy: 0.2056\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1637 - accuracy: 0.2014 - val_loss: 0.1631 - val_accuracy: 0.2033\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1628 - accuracy: 0.2007 - val_loss: 0.1623 - val_accuracy: 0.2037\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1621 - accuracy: 0.2005 - val_loss: 0.1618 - val_accuracy: 0.2045\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1616 - accuracy: 0.2002 - val_loss: 0.1614 - val_accuracy: 0.2044\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1612 - accuracy: 0.2010 - val_loss: 0.1611 - val_accuracy: 0.2037\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1610 - accuracy: 0.2011 - val_loss: 0.1608 - val_accuracy: 0.2050\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1608 - accuracy: 0.2026 - val_loss: 0.1607 - val_accuracy: 0.2060\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1606 - accuracy: 0.2028 - val_loss: 0.1606 - val_accuracy: 0.2038\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1605 - accuracy: 0.2022 - val_loss: 0.1605 - val_accuracy: 0.2025\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1604 - accuracy: 0.2015 - val_loss: 0.1604 - val_accuracy: 0.2019\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1604 - accuracy: 0.2023 - val_loss: 0.1603 - val_accuracy: 0.2028\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1603 - accuracy: 0.2030 - val_loss: 0.1603 - val_accuracy: 0.2017\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1603 - accuracy: 0.2025 - val_loss: 0.1603 - val_accuracy: 0.2012\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1602 - accuracy: 0.2033 - val_loss: 0.1602 - val_accuracy: 0.2005\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1602 - accuracy: 0.2023 - val_loss: 0.1602 - val_accuracy: 0.2004\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1602 - accuracy: 0.2028 - val_loss: 0.1602 - val_accuracy: 0.2024\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1602 - accuracy: 0.2029 - val_loss: 0.1602 - val_accuracy: 0.2027\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2033 - val_loss: 0.1601 - val_accuracy: 0.1998\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2021 - val_loss: 0.1601 - val_accuracy: 0.2040\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2035 - val_loss: 0.1601 - val_accuracy: 0.2034\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2021 - val_loss: 0.1601 - val_accuracy: 0.2020\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2031 - val_loss: 0.1601 - val_accuracy: 0.1991\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2037 - val_loss: 0.1601 - val_accuracy: 0.2013\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2038 - val_loss: 0.1601 - val_accuracy: 0.2036\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2039 - val_loss: 0.1601 - val_accuracy: 0.2016\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1601 - accuracy: 0.2042 - val_loss: 0.1601 - val_accuracy: 0.2001\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2048 - val_loss: 0.1601 - val_accuracy: 0.2035\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1601 - accuracy: 0.2051 - val_loss: 0.1601 - val_accuracy: 0.2024\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1601 - val_accuracy: 0.2026\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2053 - val_loss: 0.1601 - val_accuracy: 0.2038\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2043 - val_loss: 0.1601 - val_accuracy: 0.2044\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2042 - val_loss: 0.1601 - val_accuracy: 0.2053\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2050 - val_loss: 0.1601 - val_accuracy: 0.2008\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1601 - val_accuracy: 0.2009\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2037 - val_loss: 0.1601 - val_accuracy: 0.2035\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1601 - val_accuracy: 0.2021\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1600 - val_accuracy: 0.1986\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2044 - val_loss: 0.1600 - val_accuracy: 0.2031\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2044\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2041 - val_loss: 0.1600 - val_accuracy: 0.2008\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.1971\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2051 - val_loss: 0.1600 - val_accuracy: 0.2024\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2055 - val_loss: 0.1600 - val_accuracy: 0.2041\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2046 - val_loss: 0.1600 - val_accuracy: 0.2047\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2025\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2043 - val_loss: 0.1600 - val_accuracy: 0.2005\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2041 - val_loss: 0.1600 - val_accuracy: 0.2050\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2016\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2048 - val_loss: 0.1600 - val_accuracy: 0.2044\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2038 - val_loss: 0.1600 - val_accuracy: 0.2014\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2047 - val_loss: 0.1600 - val_accuracy: 0.2015\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2056 - val_loss: 0.1600 - val_accuracy: 0.2010\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2052 - val_loss: 0.1600 - val_accuracy: 0.2033\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2054 - val_loss: 0.1600 - val_accuracy: 0.2033\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2061 - val_loss: 0.1600 - val_accuracy: 0.2041\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2049 - val_loss: 0.1600 - val_accuracy: 0.2042\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2065 - val_loss: 0.1600 - val_accuracy: 0.1977\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2057 - val_loss: 0.1600 - val_accuracy: 0.2032\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2067 - val_loss: 0.1600 - val_accuracy: 0.2031\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2054 - val_loss: 0.1600 - val_accuracy: 0.2038\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2071 - val_loss: 0.1600 - val_accuracy: 0.2002\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2064 - val_loss: 0.1600 - val_accuracy: 0.2049\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2075 - val_loss: 0.1600 - val_accuracy: 0.2024\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2064 - val_loss: 0.1600 - val_accuracy: 0.2026\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2061 - val_loss: 0.1600 - val_accuracy: 0.2066\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2069 - val_loss: 0.1600 - val_accuracy: 0.2046\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2073 - val_loss: 0.1600 - val_accuracy: 0.2040\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2079 - val_loss: 0.1600 - val_accuracy: 0.2044\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2062 - val_loss: 0.1600 - val_accuracy: 0.2025\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2076 - val_loss: 0.1600 - val_accuracy: 0.2019\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2069 - val_loss: 0.1600 - val_accuracy: 0.2037\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2073 - val_loss: 0.1600 - val_accuracy: 0.2017\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2069 - val_loss: 0.1600 - val_accuracy: 0.2042\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2070 - val_loss: 0.1600 - val_accuracy: 0.2016\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2076 - val_loss: 0.1600 - val_accuracy: 0.2013\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2069 - val_loss: 0.1600 - val_accuracy: 0.2037\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2078 - val_loss: 0.1600 - val_accuracy: 0.2042\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2078 - val_loss: 0.1600 - val_accuracy: 0.2013\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2077 - val_loss: 0.1600 - val_accuracy: 0.2045\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2083 - val_loss: 0.1600 - val_accuracy: 0.2010\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2075 - val_loss: 0.1600 - val_accuracy: 0.2030\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2076 - val_loss: 0.1600 - val_accuracy: 0.2033\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2085 - val_loss: 0.1600 - val_accuracy: 0.2028\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2076 - val_loss: 0.1600 - val_accuracy: 0.2036\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2081 - val_loss: 0.1600 - val_accuracy: 0.2034\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2077 - val_loss: 0.1600 - val_accuracy: 0.2039\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2087 - val_loss: 0.1600 - val_accuracy: 0.2044\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2078 - val_loss: 0.1600 - val_accuracy: 0.2021\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1600 - accuracy: 0.2067 - val_loss: 0.1600 - val_accuracy: 0.2033\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1600 - accuracy: 0.2081 - val_loss: 0.1600 - val_accuracy: 0.2001\n",
      "Epoch 95/100\n",
      "567/600 [===========================>..] - ETA: 0s - loss: 0.1600 - accuracy: 0.2077"
     ]
    }
   ],
   "source": [
    "L = [2,2,2,2,3,3,3,3]\n",
    "w = [5,10,100,200,5,10,100,200]\n",
    "\n",
    "zipped = zip(L,w) # zips and creates tuples of each L and w value\n",
    "\n",
    "hist_acc_p_e = []\n",
    "hist_val_acc_p_e = []\n",
    "hist_loss_p_e = []\n",
    "hist_val_loss_p_e = []\n",
    "\n",
    "val_split = 0.1\n",
    "n_epochs = 100\n",
    "batch_size = 300\n",
    "\n",
    "for L_val,w_val in zip(L,w):\n",
    "  \n",
    "  print(\"Values: (%s, %s)\" %(int(L_val), int(w_val)))\n",
    "  print(\"-----------------------------\\n\")\n",
    "\n",
    "  model = create_p_e_model(L_val,w_val)\n",
    "\n",
    "  history_p_e = model.fit(X_train_3d,                          \n",
    "                  y_train,                          \n",
    "                  epochs=n_epochs,                  \n",
    "                  batch_size=batch_size,  \n",
    "                  validation_split=val_split\n",
    "                  )\n",
    "  pred = model.predict(X_test_3d)\n",
    "  score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
    "  print(f\"--- Final score (RMSE) : {score}\")\n",
    "  \n",
    "  # Store the performance\n",
    "  hist_acc_p_e.append(history_p_e.history['accuracy'])\n",
    "  # hist_val_acc_p_e.append(history_p_e.history['val_acc'])\n",
    "  hist_loss_p_e.append(history_p_e.history['loss'])\n",
    "  hist_val_loss_p_e.append(history_p_e.history['val_loss'])\n",
    "\n",
    "  print(\"-----------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors =['b','g','r','c','m','y','k'] # lists of color to each tuple\n",
    "\n",
    "for i, (L_val, w_val) in enumerate(zip(L, w)):\n",
    "    label = f\"({L_val}, {w_val})\"\n",
    "    color = colors[i % len(colors)] # select a color based on the index\n",
    "    plt.plot(hist_loss_p_e[i], '-|', label=label, color=color)\n",
    "    plt.plot(hist_val_loss_p_e[i], '-x', label=label, color=color)\n",
    "    \n",
    "plt.title('Model Loss on Training data')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "- It is hard to accuratly distinguish betweeen the train/val for each one, but the figure is good in order to see the comparison between the sets. However, the best performing (3,200) is the darkblue and we can see that the validation (x) started higher than the loss (|) and then they converge. This indicates that the more complex set of L and w gives the best performance with the current architecture. However, on 100 epochs. All converged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f19be9c6583db35fea0aaac514eb46c245ec0a947ce6f1f6768ef8d69014cc0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
